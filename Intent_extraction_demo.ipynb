{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intent extraction demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNG97fCc1vjSNP6dsgkFpMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wapwolf/Postcard-Generator/blob/main/Intent_extraction_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOTIDRJSqUPb",
        "outputId": "905fd17c-8ae1-4354-baf0-aa1afc59711d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (3.2.5)\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.5->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->-r requirements.txt (line 2)) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.3MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNnFF35-qZdu",
        "outputId": "59b9eab0-23b2-4b81-dcf7-38131c761c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltkmodules\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words(\"russian\"))\n",
        "\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I83eVsYolme"
      },
      "source": [
        "input_text = [\"Поздравь бабушку с пасхой. Пожелай ей всего наилучшего\",\n",
        "              \"Передай тёплые слова бабуле. Пожелай ей крепкого здоровья, удачи и успехов\",\n",
        "              \"поздравь с днём рождения бубулю. Бабуле исполнилось 98 лет. Поздравь бабулую с девяностодвухлетием! Бабушка родилась 15.02.1928\",\n",
        "              \"поздравь за меня бабку с троицей\",\n",
        "              \"поздравь ба с 8 марта!!!!!\",\n",
        "              \"поздравь бабу с рожеством\",\n",
        "              \"ПОЗДРАВЬ БАБЕНЬ С НОВЫМ ГОДОМ!!!!!11111\",\n",
        "              \"ба, с юбилеем!\"]\n",
        "\n",
        "#input_text = ['Бабушка, тебе желаю\\nСил, здоровья, красоты.\\nБудь душою молодая,\\nИ себя ты береги.\\nНаходи повсюду радость,\\nУлыбайся и мечтай.\\nВсе тревоги и усталость\\nОт себя ты отпускай.\\nПускай этот день рождения\\nСоберет вокруг родных,\\nИх любовь и уважение\\nСердце счастьем озарит.']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QCJsj8Zchl_",
        "outputId": "63969985-bfa8-4273-f598-f78557c522fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from intent_extraction_demo import *\n",
        "for text in input_text:\n",
        "    print(create_intent_dict(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "{'name': 'бабушка', 'holiday': 'пасха'}\n",
            "{'name': 'бабушка'}\n",
            "{'name': 'бабушка', 'holiday': 'день рождение', 'birth': '15.02.1928'}\n",
            "{'name': 'бабушка', 'holiday': 'троица'}\n",
            "{'name': 'бабушка', 'date': '8', 'holiday': 'март'}\n",
            "{'name': 'бабушка'}\n",
            "{'name': 'бабушка', 'holiday': 'новый год'}\n",
            "{'name': 'бабушка', 'holiday': 'юбилей'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meVu0_nYxVkA",
        "outputId": "1ddfac7d-f69b-4f88-dbff-a7a724f44fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def text_lower(text): \n",
        "    return text.lower()\n",
        "\n",
        "# remove punctuation \n",
        "def remove_punctuation(text): \n",
        "    translator = str.maketrans('', '', string.punctuation) \n",
        "    return text.translate(translator)\n",
        "\n",
        "# remove outlayer numbers\n",
        "def remove_outlayer_number(text):\n",
        "      if len(text) == 8 or len(text) == 6:\n",
        "          text = 'birth:' + '.'.join([text[:2],text[2:4],text[4:]]) # объединяем дату рождения\n",
        "\n",
        "      elif text.startswith('19'): # проверяем год ли рождения \n",
        "          text = 'birth:'+ text\n",
        "      else:\n",
        "        text = float(text)\n",
        "        if text >= 0. and text <= 31.0:\n",
        "            text= 'date:' + str(int(text)) # скорее всего это праздник вроде 8 марта\n",
        "        elif text >= 31. and text <= 110.:\n",
        "            text= 'birth:'+ str(int(text))\n",
        "        else:\n",
        "            text =  'ERR'\n",
        "            \n",
        "      return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    '''\n",
        "    Preprocesses text: \n",
        "    lowercase, tokenize, punctuation deletion, strange date deletion, overall cleaning\n",
        "\n",
        "    Input:\n",
        "    list of strings of sentences\n",
        "\n",
        "    Returns:\n",
        "    list of lists of tokens\n",
        "    ''' \n",
        "    preprocessed_text = []\n",
        "    # all to lowercase\n",
        "    text = text_lower(text)  \n",
        "\n",
        "    # sentence tokenize text                       \n",
        "    sent_list = nltk.sent_tokenize(text, language=\"russian\")  \n",
        "\n",
        "    for sent in sent_list:\n",
        "\n",
        "        #get rid of punctuation\n",
        "        sent = remove_punctuation(sent)\n",
        "\n",
        "        # get\n",
        "        token_list = nltk.word_tokenize(sent, language='russian')\n",
        "        morphed_list = [morph.parse(token)[0].normal_form for token in token_list if token not in stopwords]\n",
        "\n",
        "        # check for strange numbers and delete them\n",
        "        filtered_list = [remove_outlayer_number(token) if token.isdigit() else token  for token in morphed_list]\n",
        "\n",
        "        # #dumb check for years of birth\n",
        "        # filtered_list = [token]\n",
        "        if 'ERR' in filtered_list: filtered_list.remove('ERR')\n",
        "        preprocessed_text.append(filtered_list)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "def create_intent_dict(text):\n",
        "    ''' \n",
        "    Creates dict of intents. As a baseline\n",
        "\n",
        "    Input:\n",
        "    text is an array of arrays of strings\n",
        "\n",
        "    Returns:\n",
        "    intent_dict, dict\n",
        "\n",
        "    intent_dict structure:\n",
        "          {\n",
        "            name: str, default:\"бабушка\"\n",
        "            holiday: str (one of ['пасха', 'новый год', 'троица', 'день рождения', \n",
        "                                   '8 марта', 'рождество', 'юбилей'])  # TODO ADD MORE HOLIDAYS\n",
        "            birth: str,\n",
        "            date: str,\n",
        "          }\n",
        "    '''\n",
        "    intent_dict = {}\n",
        "    holiday_list = ['пасха', 'новый', 'троица', 'рождение', \n",
        "                    'март', 'рождество', 'юбилей']\n",
        "    intent_dict['name'] = 'бабушка'\n",
        "\n",
        "    text = preprocess_text(text) # предобрабатываем текст\n",
        "\n",
        "    for sentence in text:\n",
        "        for token in sentence:\n",
        "            if token in holiday_list:\n",
        "                if token == \"рождение\":\n",
        "                  token = 'день '+ token\n",
        "                if token == \"новый\":\n",
        "                  token = token+ \" год\"\n",
        "                intent_dict['holiday'] = token\n",
        "            if token.startswith('birth'):\n",
        "                intent_dict['birth'] = token.split(':')[1]\n",
        "            if token.startswith('date'):\n",
        "                intent_dict['date'] = token.split(':')[1]\n",
        "\n",
        "    return intent_dict\n",
        "\n",
        "\n",
        "for text in input_text:\n",
        "    print(create_intent_dict(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'бабушка', 'holiday': 'пасха'}\n",
            "{'name': 'бабушка'}\n",
            "{'name': 'бабушка', 'holiday': 'день рождение', 'birth': '15.02.1928'}\n",
            "{'name': 'бабушка', 'holiday': 'троица'}\n",
            "{'name': 'бабушка', 'date': '8', 'holiday': 'март'}\n",
            "{'name': 'бабушка'}\n",
            "{'name': 'бабушка', 'holiday': 'новый год'}\n",
            "{'name': 'бабушка', 'holiday': 'юбилей'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}